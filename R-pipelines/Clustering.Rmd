<<<<<<< HEAD:Clustering.Rmd
---
title: "Clustering"
output: html_document
date: "2023-12-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#Import libraries
library(tidyverse)
library(readxl)
library(ggplot2)
library(ggpubr)
library(ggrepel)
library(modelr)
library(devtools)
library(factoextra)
library(Rtsne)
library(umap)
library(pheatmap)
library(broom)
library(DEqMS)
library(ggvenn)
library(enrichR)
library(clusterProfiler)
library(enrichplot)
library(org.Hs.eg.db)
library(msigdbr)
library(RColorBrewer)
```

## Clustering

Groups of similar objects can also be found through clustering techniques. In this case, it could be possible to find groups of peptides or samples. Clustering algorithms estimate the degree of similarity between objects using different distance metrics. Here, two methods are explored: hierarchical and k-means clustering.

# Hierarchical clustering

Hierarchical clustering methods organize objects into a hierarchy depending on their distance from each other. This hierarchy is visualized as a dendrogram where there is one branch per sample and per peptide. This means that the result is not quite separating the data into clusters itself and the dendrogram needs to be split into clusters afterwards.

Hierarchical clustering methods can be classified as agglomerative (a.k.a., bottom-up) or divisive (a.k.a., top-down) and by the linkage method - how clusters are merged or divided - and distance metrics used. The difference between agglomerative and divisive clustering methods is that the former starts by considering each data point as an individual cluster and merges them successively based on their similarity. At each step, the most similar clusters are merged until all points belong to one cluster. On the opposite end, the divisive approach begins with all data points in a single cluster and recursively splits this cluster into smaller ones based on dissimilarity until each data point is in its cluster.

Regarding distance metrics, the euclidean approach consists of measuring the straight-line distance between two data points in a multidimensional space; while correlation-based distances measure the similarity between two variables by assessing how they change concerning each other. Commonly used correlation-based distances include Pearson and Spearman correlation. Both of them estimate the how strongly and in which direction two variables are related. However, Pearson correlation evaluates linear relationships and assumes a normal distribution, while Spearman correlation assesses monotonic relationships, providing an alternative when dealing with data that may not satisfy the assumptions of linearity or normality required by Pearson correlation (Winter, Gosling & Potter, 2016). Both have been indicated to render similar results if the data is (near) normally distributed. Since this assumption can be made for this dataset, the correlation method here used is Pearson's.

Linkage methods include single, average and complete linkage, among others. Single linkage determines the distance between two clusters based on the shortest distance between any member of one cluster and any member of the other cluster, average linkage computes the distance between clusters based on the average distance between all pairs of points in them and complete linkage measures the distance between clusters based on the maximum distance between any member of one cluster and any member of the other cluster. A problem with single linkage is the chaining effect, where long, trailing clusters or chains are formed because, looking for the shortest distance, the algorithm becomes sensitive to noise and outliers and connects clusters that should not be connected. On the opposite end, complete linkage can break up bigger clusters. In this context, average linkage can provide a compromise between the two while remaining robust (Grigorev, 2015).

To mitigate the chaining effect, other linkage methods like complete linkage (maximum linkage) or average linkage are often used. These methods tend to be less susceptible to noise and outliers and can produce more balanced, spherical clusters compared to single linkage. However, the choice of linkage method should consider the specific characteristics of the dataset and the desired properties of the resulting clusters.


```{r, echo=FALSE, warning=FALSE, message=FALSE}
class_colors <- 
  c("Pediatric" = "turquoise4",
     "Neuro" = "#7271B5",
     "Autoimmune" =  "#E95D47",
     "Cancer" = "#EAF69E",
     "Infection" = "#A5DAA4",
     "CVD" = "#9E0142",
     "Healthy" = "grey2")

disease_colors <- c("Acute.coronary.syndrome" = "#9E0142", "Bipolar.disorder" =  "#5E4FA2", "Chronic.Liver.Disease..CLD." = "#B41A47", "Fatty.Liver.Disease"="#CB334C", "Healthy" = "grey2", "Hepatocellular.cancer" = "#EAF69E", "Melanoma" = "#D7EF9B", "Multiple.sclerosis"= "#FCA85E", "Myositis" = "#F4FAAE", "NA"= "white", "NAFLD" = "#DC494C", "Necrotizing.soft.tissue.infection"= "#A5DAA4", "Obesity" = "#E95D47", "Occlusion.or.stenosis.of.the.carotid.artery" = "#F47245", "Pancreatic.cancer"= "#BEE5A0", "Pediatric.Diseases" = "#3F96B7", "Pneumonia" = "#88CFA4", "Pyelonephritis" ="#6BC4A4", "Rheumatoid.arthritis" = "#FDBE6E", "Schizophrenia" =  "#4B66AD", "Scleroderma"= "#FDD380", "Sepsis" = "#54AEAC", "Sjögrens.syndrome" = "#FEE593", "Systemisk.Lupus.Erythematosus" = "#FEF2A9", "Venous.thromboembolism" = "#F88D51", "Venous.thromboembolism..suspected." = "#F88D51", "Viral.hepatitis.related.cirrhosis"= "#FFFFBF")

disease_shapes <- c("Acute.coronary.syndrome" = 1, "Bipolar.disorder" =  2, "Chronic.Liver.Disease..CLD." = 3, "Fatty.Liver.Disease"=4, "Healthy" = 5, "Hepatocellular.cancer" = 6, "Melanoma" = 7, "Multiple.sclerosis"= 8, "Myositis" = 9, "NA"= 10, "NAFLD" = 11, "Necrotizing.soft.tissue.infection"= 12, "Obesity" = 13, "Occlusion.or.stenosis.of.the.carotid.artery" = 14, "Pancreatic.cancer"= 15, "Pediatric.Diseases" = 16, "Pneumonia" = 16, "Pyelonephritis" =17, "Rheumatoid.arthritis" = 18, "Schizophrenia" =  19, "Scleroderma"= 20, "Sepsis" = 21, "Sjögrens.syndrome" = 22, "Systemisk.Lupus.Erythematosus" = 23, "Venous.thromboembolism" = 24, "Venous.thromboembolism..suspected." = 24, "Viral.hepatitis.related.cirrhosis"= 25)


```

```{r, all_heatmap, fig.width=15, fig.height=10, echo=FALSE, warning=FALSE, message=FALSE}

temp_quant_data <- read.csv("sample-feature.csv")
additional_info <- read_xlsx("220411_SampleManifest_Olink_DA3.xlsx")

#Filter peptides that appear in less than 50% of the samples

# Calculate the threshold for 50% of samples
threshold <- ncol(temp_quant_data) * 0.5

# Filter rows that have data for at least 50% of the samples
quant_data <- temp_quant_data[rowSums(!is.na(temp_quant_data)) >= threshold, ]

# Extracting sample, disease, and class from column names
col_ann <- data.frame(colnames(quant_data)) %>%
  separate(col = "colnames.quant_data.", into = c("sample_id", "Disease", "Class"), sep = "_")

col_ann <- merge(col_ann, additional_info[c("sample_id", "target_plate")], by = "sample_id", all.x = TRUE)

# Remove the first row which contains the original column names
col_ann <- col_ann[-1, ]

# Set row names using the 'Sample' column
rownames(col_ann) <- col_ann$sample_id

# Remove the 'Sample' column to avoid duplication
col_ann <- col_ann[, -1]

#Get the right format for the quantification data
# Store the second column as row names
row_names <- quant_data[[1]]

# Remove the second column from the dataset
quant_data <- quant_data[,-1]

# Set the values from the second column as row names
rownames(quant_data) <- row_names

colnames(quant_data) <- gsub("_.*$", "", colnames(quant_data))

## 1- Pearson correlation as distance metric

imputed_quant_data <- apply(quant_data, 2, function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x))

# Cluster samples (columns)
cor_col <- cor(imputed_quant_data, method = 'pearson')
dist_col <- as.dist(1-cor_col)

# Cluster proteins (rows)
cor_row <- cor(t(imputed_quant_data), method = 'pearson')
dist_row <- as.dist(1-cor_row)

# Plot heatmap
all_pep_heatmap <- pheatmap(as.matrix(imputed_quant_data),
         width = 24,  # Adjust the width of the plot
         height = 20,  # Adjust the height of the plot
         breaks = seq(-2, 2, length.out = 101),
         scale = 'row',
         clustering_distance_cols = dist_col,
         clustering_distance_rows = dist_row,
         clustering_method = 'average',
         annotation_col = col_ann,
         show_colnames = F,
         border_color = NA,
         annotation_colors = list(Disease = disease_colors, Class = class_colors),
         #color = viridis::inferno(20, direction = -1),
         fontsize = 4,
         fontsize_row = 2,
         fontzise_col = 4,
         angle_col = 90,
         main = 'Pearson correlation distance')

svg("all_pep_heatmap.svg", width = 15, height = 8)
all_pep_heatmap
dev.off()

all_pep_heatmap
```


```{r, highest_pep_heatmap, fig.width=15, fig.height=10, echo=FALSE, warning=FALSE, message=FALSE}

# Filter rows that have data for at least 50% of the samples
quant_data <- temp_quant_data[rowSums(!is.na(temp_quant_data)) >= threshold, ]

#Getting mean per peptide across the dataset
#Temporary dataset with only the peptide names
data_temp <- separate(quant_data, "X", into = c("Protein", "Peptide"), sep = "-")
data_temp_2 <- data_temp[, -(1:2)]
rownames(data_temp_2) <- data_temp$Peptide
 
peptide_means <- rowMeans(data_temp_2, na.rm = TRUE)
data_temp$pep_means <- peptide_means

# Group by 'Protein' and filter rows where 'pep_means' is equal to the maximum 'pep_means'
highest_pep <- data_temp %>%
  group_by(Protein) %>%
  filter(pep_means == max(pep_means))

highest_pep <- unite(highest_pep, "protein-peptide", c("Protein", "Peptide"), sep = "-")
highest_pep <- column_to_rownames(highest_pep, var = "protein-peptide")
highest_pep <- highest_pep[, -ncol(highest_pep)]

# Extracting sample, disease, and class from column names
col_ann <- data.frame(colnames(highest_pep)) %>%
  separate(col = "colnames.highest_pep.", into = c("sample_id", "Disease", "Class"), sep = "_")

colnames(highest_pep) <- gsub("_.*$", "", colnames(highest_pep))


imputed_highest_pep <- apply(highest_pep, 2, function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x))

col_ann <- merge(col_ann, additional_info[c("sample_id", "target_plate")], by = "sample_id", all.x = TRUE)

# Set row names using the 'sample_id' column
rownames(col_ann) <- col_ann$sample_id

# Remove the 'sample_id' column to avoid duplication
col_ann <- col_ann[, -1]


# Cluster samples (columns)
cor_col <- cor(imputed_highest_pep, method = 'pearson')
dist_col <- as.dist(1 - cor_col)

# Cluster proteins (rows)
cor_row <- cor(t(imputed_highest_pep), method = 'pearson')
dist_row <- as.dist(1 - cor_row)

# Plot heatmap
max_pep_heatmap <- pheatmap(as.matrix(imputed_highest_pep),
         width = 24,  # Adjust the width of the plot
         height = 20,  # Adjust the height of the plot
         breaks = seq(-2, 2, length.out = 101),
         scale = 'row',
         clustering_distance_cols = dist_col,
         clustering_distance_rows = dist_row,
         clustering_method = 'average',
         annotation_col = col_ann,
         show_colnames = F,
         border_color = NA,
         annotation_colors =list(Class =  class_colors, Disease=disease_colors),
         #color = viridis::inferno(20, direction = -1),
         fontsize = 6,
         fontsize_row = 2,
         fontzise_col = 4,
         angle_col = 90,
         main = 'Pearson correlation distance')

svg("max_pep_heatmap.svg", width = 15, height = 8)
max_pep_heatmap
dev.off()

max_pep_heatmap
```


# References

De Winter, J. C., Gosling, S. D., & Potter, J. (2016). Comparing the Pearson and Spearman correlation coefficients across distributions and sample sizes: A tutorial using simulations and empirical data. *Psychological methods, 21*(3), 273.

Grigorev, A. (2015, June 5). *Agglomerative clustering*. ML wiki. http://mlwiki.org/index.php/Agglomerative_Clustering 
=======
---
title: "Clustering"
output: html_document
date: "2023-12-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#Import libraries
library(tidyverse)
library(readxl)
library(ggplot2)
library(ggpubr)
library(ggrepel)
library(modelr)
library(devtools)
library(factoextra)
library(Rtsne)
library(umap)
library(pheatmap)
library(broom)
library(DEqMS)
library(ggvenn)
library(enrichR)
library(clusterProfiler)
library(enrichplot)
library(org.Hs.eg.db)
library(msigdbr)
library(RColorBrewer)
```

## Clustering

Groups of similar objects can also be found through clustering techniques. In this case, it could be possible to find groups of peptides or samples. Clustering algorithms estimate the degree of similarity between objects using different distance metrics. Here, two methods are explored: hierarchical and k-means clustering.

# Hierarchical clustering

Hierarchical clustering methods organize objects into a hierarchy depending on their distance from each other. This hierarchy is visualized as a dendrogram where there is one branch per sample and per peptide. This means that the result is not quite separating the data into clusters itself and the dendrogram needs to be split into clusters afterwards.

Hierarchical clustering methods can be classified as agglomerative (a.k.a., bottom-up) or divisive (a.k.a., top-down) and by the linkage method - how clusters are merged or divided - and distance metrics used. Linkage methods include single, average and complete linkage, among others. Euclidean and correlation-based distances are some of the most common ones. 

The difference between agglomerative and divisive clustering methods is that the former starts by considering each data point as an individual cluster and merges them successively based on their similarity. At each step, the most similar clusters are merged until all points belong to one cluster. On the opposite end, the divisive approach begins with all data points in a single cluster and recursively splits this cluster into smaller ones based on dissimilarity until each data point is in its cluster.

Regarding distance metrics, the euclidean approach consists of measuring the straight-line distance between two data points in a multidimensional space; while correlation-based distances measure the similarity between two variables by assessing how they change concerning each other. Commonly used correlation-based distances include Pearson and Spearman correlation.

Finally, single linkage determines the distance between two clusters based on the shortest distance between any member of one cluster and any member of the other cluster, average linkage computes the distance between clusters based on the average distance between all pairs of points in them and complete linkage measures the distance between clusters based on the maximum distance between any member of one cluster and any member of the other cluster.



```{r, echo=FALSE, warning=FALSE, message=FALSE}
class_colors <- 
  c("Pediatric" = "turquoise4",
     "Neuro" = "#7271B5",
     "Autoimmune" =  "#E95D47",
     "Cancer" = "#EAF69E",
     "Infection" = "#A5DAA4",
     "CVD" = "#9E0142",
     "Healthy" = "grey2")

disease_colors <- c("Acute.coronary.syndrome" = "#9E0142", "Bipolar.disorder" =  "#5E4FA2", "Chronic.Liver.Disease..CLD." = "#B41A47", "Fatty.Liver.Disease"="#CB334C", "Healthy" = "grey2", "Hepatocellular.cancer" = "#EAF69E", "Melanoma" = "#D7EF9B", "Multiple.sclerosis"= "#FCA85E", "Myositis" = "#F4FAAE", "NA"= "white", "NAFLD" = "#DC494C", "Necrotizing.soft.tissue.infection"= "#A5DAA4", "Obesity" = "#E95D47", "Occlusion.or.stenosis.of.the.carotid.artery" = "#F47245", "Pancreatic.cancer"= "#BEE5A0", "Pediatric.Diseases" = "#3F96B7", "Pneumonia" = "#88CFA4", "Pyelonephritis" ="#6BC4A4", "Rheumatoid.arthritis" = "#FDBE6E", "Schizophrenia" =  "#4B66AD", "Scleroderma"= "#FDD380", "Sepsis" = "#54AEAC", "Sjögrens.syndrome" = "#FEE593", "Systemisk.Lupus.Erythematosus" = "#FEF2A9", "Venous.thromboembolism" = "#F88D51", "Venous.thromboembolism..suspected." = "#F88D51", "Viral.hepatitis.related.cirrhosis"= "#FFFFBF")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}

temp_quant_data <- read.csv("sample-feature.csv")
additional_info <- read_xlsx("220411_SampleManifest_Olink_DA3.xlsx")

#Filter peptides that appear in less than 50% of the samples

# Calculate the threshold for 50% of samples
threshold <- ncol(temp_quant_data) * 0.5

# Filter rows that have data for at least 50% of the samples
quant_data <- temp_quant_data[rowSums(!is.na(temp_quant_data)) >= threshold, ]

# Extracting sample, disease, and class from column names
col_ann <- data.frame(colnames(quant_data)) %>%
  separate(col = "colnames.quant_data.", into = c("sample_id", "Disease", "Class"), sep = "_")

col_ann <- merge(col_ann, additional_info[c("sample_id", "target_plate")], by = "sample_id", all.x = TRUE)

# Remove the first row which contains the original column names
col_ann <- col_ann[-1, ]

# Set row names using the 'Sample' column
rownames(col_ann) <- col_ann$sample_id

# Remove the 'Sample' column to avoid duplication
col_ann <- col_ann[, -1]

#Get the right format for the quantification data
# Store the second column as row names
row_names <- quant_data[[1]]

# Remove the second column from the dataset
quant_data <- quant_data[,-1]

# Set the values from the second column as row names
rownames(quant_data) <- row_names

colnames(quant_data) <- gsub("_.*$", "", colnames(quant_data))

## 1- Pearson correlation as distance metric

imputed_quant_data <- apply(quant_data, 2, function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x))

# Cluster samples (columns)
cor_col <- cor(imputed_quant_data, method = 'pearson')
dist_col <- as.dist(1-cor_col)

# Cluster proteins (rows)
cor_row <- cor(t(imputed_quant_data), method = 'pearson')
dist_row <- as.dist(1-cor_row)

# Plot heatmap
all_pep_heatmap <- pheatmap(as.matrix(imputed_quant_data),
         width = 24,  # Adjust the width of the plot
         height = 20,  # Adjust the height of the plot
         breaks = seq(-2, 2, length.out = 101),
         scale = 'row',
         clustering_distance_cols = dist_col,
         clustering_distance_rows = dist_row,
         clustering_method = 'average',
         annotation_col = col_ann,
         show_colnames = F,
         border_color = NA,
         annotation_colors = list(Disease = disease_colors, Class = class_colors),
         #color = viridis::inferno(20, direction = -1),
         fontsize = 4,
         fontsize_row = 2,
         fontzise_col = 4,
         angle_col = 90,
         main = 'Pearson correlation distance')

svg("all_pep_heatmap.svg", width = 25, height = 20)
all_pep_heatmap
dev.off()

all_pep_heatmap
```


```{r, highest_pep_heatmap, echo=FALSE}

# Filter rows that have data for at least 50% of the samples
quant_data <- temp_quant_data[rowSums(!is.na(temp_quant_data)) >= threshold, ]

#Getting mean per peptide across the dataset
#Temporary dataset with only the peptide names
data_temp <- separate(quant_data, "X", into = c("Protein", "Peptide"), sep = "-")
data_temp_2 <- data_temp[, -(1:2)]
rownames(data_temp_2) <- data_temp$Peptide
 
peptide_means <- rowMeans(data_temp_2, na.rm = TRUE)
data_temp$pep_means <- peptide_means

# Group by 'Protein' and filter rows where 'pep_means' is equal to the maximum 'pep_means'
highest_pep <- data_temp %>%
  group_by(Protein) %>%
  filter(pep_means == max(pep_means))

highest_pep <- unite(highest_pep, "protein-peptide", c("Protein", "Peptide"), sep = "-")
highest_pep <- column_to_rownames(highest_pep, var = "protein-peptide")
highest_pep <- highest_pep[, -ncol(highest_pep)]

# Extracting sample, disease, and class from column names
col_ann <- data.frame(colnames(highest_pep)) %>%
  separate(col = "colnames.highest_pep.", into = c("sample_id", "Disease", "Class"), sep = "_")

colnames(highest_pep) <- gsub("_.*$", "", colnames(highest_pep))


imputed_highest_pep <- apply(highest_pep, 2, function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x))

col_ann <- merge(col_ann, additional_info[c("sample_id", "target_plate")], by = "sample_id", all.x = TRUE)

# Set row names using the 'sample_id' column
rownames(col_ann) <- col_ann$sample_id

# Remove the 'sample_id' column to avoid duplication
col_ann <- col_ann[, -1]


# Cluster samples (columns)
cor_col <- cor(imputed_highest_pep, method = 'pearson')
dist_col <- as.dist(1 - cor_col)

# Cluster proteins (rows)
cor_row <- cor(t(imputed_highest_pep), method = 'pearson')
dist_row <- as.dist(1 - cor_row)

# Plot heatmap
max_pep_heatmap <- pheatmap(as.matrix(imputed_highest_pep),
         width = 24,  # Adjust the width of the plot
         height = 20,  # Adjust the height of the plot
         breaks = seq(-2, 2, length.out = 101),
         scale = 'row',
         clustering_distance_cols = dist_col,
         clustering_distance_rows = dist_row,
         clustering_method = 'average',
         annotation_col = col_ann,
         show_colnames = F,
         border_color = NA,
         annotation_colors =list(Class =  class_colors, Disease=disease_colors),
         #color = viridis::inferno(20, direction = -1),
         fontsize = 6,
         fontsize_row = 2,
         fontzise_col = 4,
         angle_col = 90,
         main = 'Pearson correlation distance')

svg("max_pep_heatmap.svg", width = 25, height = 20)
max_pep_heatmap
dev.off()

max_pep_heatmap
```

>>>>>>> 77d33f3f9e4068510419f6549665fbb5f45e87ed:R-pipelines/Clustering.Rmd
